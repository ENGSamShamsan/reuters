{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D conv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv1d - Maxpool\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, nr_filters, filter_size, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.Embedding(num_embeddings, : size of the dictionary of embeddings\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=embedding_dim)\n",
    "                \n",
    "        self.conv1 = nn.Conv1d(in_channels=50, out_channels=nr_filters, kernel_size=filter_size)\n",
    "        self.fc = nn.Linear(in_features= nr_filters, out_features= output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        \n",
    "        self.nr_filters = nr_filters\n",
    "        self.printmore= torch.zeros(1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        self.printmore=1\n",
    "        \n",
    "        if self.printmore:\n",
    "            print('Begin -------')\n",
    "            print(f'input x: {x.shape}')\n",
    "        # x.shape [574, 64], [textlen for current batch, batch_size], textlen varies by batch\n",
    "  \n",
    "\n",
    "        # Permute to put batch first, to (N,W)\n",
    "        x = x.permute(1, 0)\n",
    "        if self.printmore:\n",
    "            print(f'After permute: {x.shape}') # [64, 574], [batch, textlen]\n",
    "\n",
    "        # EMBEDDING\n",
    "        # nn.Embedding. input (N, W) mini-batch, Words per... out:(N, W, emb_dim)      \n",
    "        x = self.embedding(x)\n",
    "        if self.printmore:\n",
    "            print(f'Embedded: {x.shape}') # [64, 574, 50], [batch, textlen, emb_dim]\n",
    "        \n",
    "        # CONVOLUTION\n",
    "        #Weight we get is size [128, 1, 5], [nr_channels, in_chan, filter_size]\n",
    "        \n",
    "        #Conv input [batch, in_channels=, textlen, emb_dim]\n",
    "        # chance dim 1 and 2 with each other, textlen and emb_dim\n",
    "        x = x.transpose(1,2)\n",
    "        if self.printmore:\n",
    "            print(f'Textlen, emb switched with transpose: {x.shape}')     \n",
    "        \n",
    "        x = self.conv1(x)   \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        if self.printmore:\n",
    "            print(f'After conv1d: {x.shape}')   \n",
    "        \n",
    "        #print(x.shape) # [64, 128, 1091] [batch, filters, nr_steps filter took]\n",
    "        \n",
    "        x = F.max_pool1d(x, x.size(2))          #print(x.shape) # [64, 128, 1]\n",
    "        x = x.squeeze(2) # squeezes the last 1 dim away\n",
    "        if self.printmore:\n",
    "            print(f'After max_pool1d+squeeze(2): {x.shape}') #   [batch, nr_filters] [64, 128]  \n",
    "       \n",
    "        x = self.dropout(x)        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        #x = F.sigmoid(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D conv MAX + AVG Pool concatenated\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, nr_filters, filter_size, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.Embedding(num_embeddings, : size of the dictionary of embeddings\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=embedding_dim)\n",
    "        \n",
    "        # 1 layer conv\n",
    "        self.conv1 = nn.Conv1d(in_channels=50, out_channels=nr_filters, kernel_size=filter_size)      \n",
    "        #self.conv1_bn = nn.BatchNorm2d(nr_filters)\n",
    "        self.fc = nn.Linear(in_features= nr_filters*2, out_features= output_dim)\n",
    "        \n",
    "        # 2 layers conv\n",
    "        #self.conv1 = nn.Conv1d(in_channels=50, out_channels=nr_filters, kernel_size=filter_size)\n",
    "        #self.conv2 = nn.Conv1d(in_channels= nr_filters, out_channels=nr_filters*2, kernel_size=filter_size )\n",
    "        #self.fc = nn.Linear(in_features= nr_filters*2, out_features= output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        \n",
    "        self.nr_filters = nr_filters\n",
    "        self.printmore= torch.zeros(1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        self.printmore=0\n",
    "        \n",
    "        if self.printmore:\n",
    "            print('Begin -------')\n",
    "            print(f'input x: {x.shape}')\n",
    "            # x.shape [574, 64], [textlen for current batch, batch_size], textlen varies by batch      \n",
    "  \n",
    "\n",
    "        # Permute to put batch first, to (N,W)\n",
    "        x = x.permute(1, 0)\n",
    "        if self.printmore:\n",
    "            print(f'After permute: {x.shape}') # [64, 574], [batch, textlen]\n",
    "\n",
    "            \n",
    "        # EMBEDDING\n",
    "        # nn.Embedding. input (N, W) mini-batch, Words per... out:(N, W, emb_dim)      \n",
    "        x = self.embedding(x)\n",
    "        if self.printmore:\n",
    "            print(f'Embedded: {x.shape}') # [64, 574, 50], [batch, textlen, emb_dim]\n",
    "        \n",
    "        # CONVOLUTION\n",
    "        #Weight we get is size [128, 1, 5], [nr_channels, in_chan, filter_size]\n",
    "        \n",
    "        #Conv input [batch, in_channels=, textlen, emb_dim]\n",
    "        # chance dim 1 and 2 with each other, textlen and emb_dim\n",
    "        x = x.transpose(1,2)\n",
    "        if self.printmore:\n",
    "            print(f'Textlen, emb switched with transpose: {x.shape}')     \n",
    "        \n",
    "        x = self.conv1(x)           \n",
    "        # = self.conv1_bn(self.conv1(x))\n",
    "        if self.printmore:\n",
    "            print(f'After conv1d: {x.shape}')   \n",
    "        \n",
    "            #print(x.shape) # [64, 128, 1091] [batch, filters, nr_steps filter took]\n",
    "            \n",
    "        #x = self.conv2(x)    \n",
    "\n",
    "        #x = F.max_pool1d(x, x.size(2))          #print(x.shape) # [64, 128, 1]\n",
    "        #x = x.squeeze(2) # squeezes the last 1 dim away\n",
    "\n",
    "        # max + avg pool and concat\n",
    "        # This will features 2* long, so next layer needs to input 2*len\n",
    "        p1 = F.max_pool1d(x, x.size(2)).squeeze(2)          #print(x.shape) # [64, 128, 1]\n",
    "        p2 = F.max_pool1d(x, x.size(2)).squeeze(2)          #print(x.shape) # [64, 128, 1]\n",
    "        x = torch.cat((p1,p2), 1)\n",
    "        \n",
    "        \n",
    "        if self.printmore:\n",
    "            print(f'After max_pool1d+squeeze(2): {x.shape}') #   [batch, nr_filters] [64, 128]  \n",
    "       \n",
    "        x = F.relu(x)        \n",
    "       \n",
    "        x = self.dropout(x)        \n",
    "        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        #x = F.sigmoid(x)\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling\n",
    "VOCAB_SIZE=len(TEXT.vocab) # 25002\n",
    "EMBEDDING_DIM=50\n",
    "\n",
    "NR_FILTERS=128 \n",
    "FILTER_SIZE = 5\n",
    "OUTPUT_DIM = 126\n",
    "\n",
    "model = CNN(VOCAB_SIZE, EMBEDDING_DIM, NR_FILTERS, FILTER_SIZE, OUTPUT_DIM)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D conv model, with multi size kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n",
    "        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        x = x.permute(1, 0)\n",
    "                \n",
    "        #x = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 126\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "N_FILTERS = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "OUTPUT_DIM = 126\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# 14 epochs gave f1 0.84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
