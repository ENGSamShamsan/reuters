{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Text project\n",
    "\n",
    "**Due Thursday, December 13, before 23:59.**\n",
    "\n",
    "The task is to learn to assign the correct labels to news articles.  The corpus contains ~850K articles from Reuters.  The test set is about 10% of the articles. The data is unextracted in XML files.\n",
    "\n",
    "We're only giving you the code for downloading the data, and how to save the final model. The rest you'll have to do yourselves.\n",
    "\n",
    "Some comments and hints particular to the project:\n",
    "\n",
    "- One document may belong to many classes in this problem, i.e., it's a multi-label classification problem. In fact there are documents that don't belong to any class, and you should also be able to handle these correctly. Pay careful attention to how you design the outputs of the network (e.g., what activation to use) and what loss function should be used.\n",
    "- You may use word-embeddings to get better results. For example, you were already using a smaller version of the GloVE  embeddings in exercise 4. Do note that these embeddings take a lot of memory. \n",
    "- In the exercises we used e.g., `torchvision.datasets.MNIST` to handle the loading of the data in suitable batches. Here, you need to handle the dataloading yourself.  The easiest way is probably to create a custom `Dataset`. [See for example here for a tutorial](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added alphabetical sorting of test files + reading newsid tag and sorting by it for test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "384MB [00:50, 12.2MB/s]                           "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "import zipfile\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_zipfile(filepath):  \n",
    "    '''\n",
    "    read and parse contents of single zipfile (with about 100+ xml-files in it)\n",
    "    fields: headline, text, classes\n",
    "    return them as list\n",
    "    '''\n",
    "    this_documents=[]\n",
    "    \n",
    "    zf = zipfile.ZipFile(filepath, 'r')    \n",
    "\n",
    "    # for all xml-files within a zip\n",
    "    for name in zf.namelist():\n",
    "        #if name.endswith('xml'): continue\n",
    "    \n",
    "        infile = zf.open(name)    \n",
    "        contents = infile.read()\n",
    "        soup = BeautifulSoup(contents,'lxml')\n",
    "    \n",
    "        headline = soup.find('headline')\n",
    "        text = soup.find('text')       #print(headline.get_text())\n",
    "    \n",
    "    # extract all topic-classes \n",
    "    # only take \"codes\" by topic, not region or industry: class == 'bip:topics:1.0'\n",
    "        classcodes = []\n",
    "        for element in soup.find_all('codes', class_='bip:topics:1.0'):\n",
    "            for code in element.find_all('code'):\n",
    "                clas = code['code']\n",
    "                #print(clas)\n",
    "                classcodes.append(clas)\n",
    "\n",
    "        this_documents.append({'headline': headline.get_text(), 'text': text.get_text(), 'codes': classcodes})\n",
    "    return this_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41.0k/384M [00:00<16:41, 383kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.helsinki.fi/u/jgpyykko/reuters.zip to train/reuters.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 384M/384M [00:31<00:00, 12.2MB/s] "
     ]
    }
   ],
   "source": [
    "train_path = 'train/'\n",
    "\n",
    "dl_file='reuters.zip'\n",
    "dl_url='https://www.cs.helsinki.fi/u/jgpyykko/'\n",
    "zip_path = os.path.join(train_path, dl_file)\n",
    "if not os.path.isfile(zip_path):\n",
    "    download_url(dl_url + dl_file, root=train_path, filename=dl_file, md5=None)\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as zip_f:\n",
    "    zip_f.extractall(train_path)\n",
    "    #os.unlink(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command downloads and extracts the data files into the `train` subdirectory.\n",
    "\n",
    "The files can be found in `train/`, and are named as `19970405.zip`, etc. You will have to manage the content of these zips to get the data. There is a readme which has links to further descriptions on the data.\n",
    "\n",
    "The class labels, or topics, can be found in the readme file called `train/codes.zip`.  The zip contains a file called \"topic_codes.txt\".  This file contains the special codes for the topics (about 130 of them), and the explanation - what each code means.  \n",
    "\n",
    "The XML document files contain the article's headline, the main body text, and the list of topic labels assigned to each article.  You will have to extract the topics of each article from the XML.  For example: \n",
    "&lt;code code=\"C18\"&gt; refers to the topic \"OWNERSHIP CHANGES\" (like a corporate buyout).\n",
    "\n",
    "You should pre-process the XML to extract the words from the article: the &lt;headline&gt; element and the &lt;text&gt;.  You should not need any other parts of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CLASS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one of the Class-code files\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile('train/REUTERS_CORPUS_2/codes.zip', 'r') \n",
    "colnames=['Code','Description']\n",
    "df = pd.read_csv(zf.open('topic_codes.txt'), skiprows=2, error_bad_lines=True, \n",
    "                 header=None, names=colnames, sep='\\t')\n",
    "\n",
    "# df # (the file has 2 first rows as CODE/DESCRIPTION, the extra line is still at row 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df.to_csv('input/classcodes.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "classcodes= pd.read_csv('input/classcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REUTER EC REPORT LONG-TERM DIARY FOR APR 7 - DEC 31, 1997.\n",
      "\n",
      "****\n",
      "HIGHLIGHTS\n",
      "****\n",
      "AMSTERDAM - The Netherlands hosts summit of European Union leaders (June 16-17).\n",
      "MADRID - NATO holds summit to set the course for enlargement (July 8 and 9).\n",
      "LUXEMBOURG - Luxembourg hosts summit of European Union leaders (December 12-13).\n",
      "APRIL\n",
      "BRUSSELS (MODIFIED ITEM) - Conference of Bosnian donor countries originally scheduled for April has been POSTPONED to an unspecified date before June.\n",
      "MONDAY, APRIL 7\n",
      "NOORDWIJK, Netherlands (NEW ITEM) - EU foreign ministers hold conclave on the inter-governmental conference (second of two days).\n",
      "NOORDWIJK, Netherlands (EXPANDED ITEM) - EU-Rio Group meeting involving South American countries and Mexico, Panama, Trinidad, Tobago and Costa Rica (To April 8). Honduras, Guyana and chairmen of the Organisation of American States, the InterAmerican Development Bank, Latin American Parliament, the Institute for European-Latin American Relations, the European Investment Bank also attend. Discussions focus on political developments i\n"
     ]
    }
   ],
   "source": [
    "# example http://www2.hawaii.edu/~takebaya/cent110/xml_parse/xml_parse.html\n",
    "\n",
    "# testing\n",
    "# unzip a single xml first\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "infile = open(\"train/477886newsML.xml\",\"r\")\n",
    "contents = infile.read()\n",
    "soup = BeautifulSoup(contents,'lxml') # use parser lxml as parser xml returns empty list\n",
    "\n",
    "headline = soup.find('headline')\n",
    "print(headline.get_text())\n",
    "\n",
    "text = soup.find('text')\n",
    "print(text.get_text()[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477886\n"
     ]
    }
   ],
   "source": [
    "# Get newsid - number of article\n",
    "hrefs = soup.find_all('newsitem')\n",
    "for href in hrefs:\n",
    "    print(href.get('itemid'))\n",
    "    #print href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes = soup.find_all('code')\n",
    "# for code in codes:\n",
    "#     print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to topic_codes.txt inside codes.zip, Which defines that \n",
    "\n",
    "G15 EUROPEAN COMMUNITY \n",
    "\n",
    "GCAT\tGOVERNMENT/SOCIAL\n",
    "\n",
    "EEC is found in region_codes.txt: EEC\tEUROPEAN UNION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take codes by topic, not region or industry\n",
    "# codes = soup.find_all('codes', class_='bip:topics:1.0')\n",
    "# for code in codes:\n",
    "#     print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G15\n",
      "GCAT\n"
     ]
    }
   ],
   "source": [
    "# extract all topic-classes \n",
    "# only take \"codes\" by topic, not region or industry: class == 'bip:topics:1.0'\n",
    "# example\n",
    "# <codes class=\"bip:topics:1.0\">\n",
    "# <code code=\"G15\"> ... </code>\n",
    "# <code code=\"GCAT\"> ... </code>\n",
    "# </codes>\n",
    "for element in soup.find_all('codes', class_='bip:topics:1.0'):\n",
    "    for code in element.find_all('code'):\n",
    "        clas = code['code']\n",
    "        print(clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "['19970722.zip', '19970508.zip', '19970421.zip', '19970612.zip']\n"
     ]
    }
   ],
   "source": [
    "# get list of *.zip files in dir, such that contain xml-files (name starts with 1).\n",
    "dirpath = 'train/REUTERS_CORPUS_2/'\n",
    "files = [f for f in os.listdir(dirpath) if os.path.isfile(os.path.join(dirpath, f))]\n",
    "# cut out codes.zip, readme.txt etc. All zips containing .xml start with 1\n",
    "filenames_zip = [f for f in files if '1' in f]\n",
    "print(len(filenames_zip))\n",
    "print(filenames_zip[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get xml-filenames inside a single zip-file\n",
    "mypath = 'train/REUTERS_CORPUS_2/'\n",
    "file = '19970722.zip'\n",
    "zf = zipfile.ZipFile(mypath+file, 'r')\n",
    "\n",
    "# get names of all xml-files within a zip\n",
    "# for name in zf.namelist():    \n",
    "    # print(name)    \n",
    "    #f = zf.open(name)\n",
    "    #print(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read single zipfiles contents\n",
    "mypath = 'train/REUTERS_CORPUS_2/'\n",
    "documents= []    \n",
    "\n",
    "file = '19970722.zip'\n",
    "\n",
    "documents.extend( read_one_zipfile(mypath+file) )\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small = pd.DataFrame(documents)\n",
    "# data_small[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - faster test with cutting list to 2 zipfiles\n",
    "#filenames_zip = filenames_zip[0:2]\n",
    "#filenames_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299773"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAN TAKE ABOUT 30-60 MIN!\n",
    "# Read all zipfiles\n",
    "mypath = 'train/REUTERS_CORPUS_2/'\n",
    "documents= []\n",
    "\n",
    "ind_8 = 0\n",
    "for i, file in enumerate(filenames_zip):\n",
    "    if i == 8:\n",
    "        ind_8 = len(documents)\n",
    "    documents.extend( read_one_zipfile(mypath+file) )\n",
    "len(documents)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(documents)\n",
    "# data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn classnames into integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### string-to-int and int-to-string dictionaries for classcodes, turn classes into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '1POL'),\n",
       " (1, '2ECO'),\n",
       " (2, '3SPO'),\n",
       " (3, '4GEN'),\n",
       " (4, '6INS'),\n",
       " (5, '7RSK'),\n",
       " (6, '8YDB')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itocode.items())[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4GEN\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(itocode[3])\n",
    "print(codetoi['4GEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn one list of codes into ints\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "#test\n",
    "listToInt(['C18', 'C181', 'CCAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               codes                                           headline  \\\n",
      "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
      "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
      "2        [G15, GCAT]  Official Journal contents - OJ L 190 of July 1...   \n",
      "\n",
      "                                                text       classes  \n",
      "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]  \n",
      "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]  \n",
      "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]  \n"
     ]
    }
   ],
   "source": [
    "# for each list of codes, turn it to ints\n",
    "reuters = data_small\n",
    "\n",
    "reuters['classes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "data_small = reuters\n",
    "print(reuters[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters2 = pd.DataFrame(data.loc[:ind_8])\n",
    "reuters2['classes'] = [listToInt(codelist) for codelist in reuters2.codes]\n",
    "data_8 = reuters2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad with -1 for given length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for pytorch nn.MultiLabelMarginLoss(), which expects labels in start, then -1 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, '-1', '-1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad list with -1 to given length\n",
    "def padList(mylist, length=10):\n",
    "\n",
    "    mylist = (mylist + length*['-1'])[:length]\n",
    "    return mylist\n",
    "\n",
    "#test\n",
    "padList([2,3],length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2        [G15, GCAT]  Official Journal contents - OJ L 190 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each list of codes, pad it\n",
    "reuters = data_small\n",
    "\n",
    "reuters['classes_pad'] = padList(reuters['classes'], length=10)\n",
    "data_small = reuters\n",
    "reuters[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save small example-table to pickle\n",
    "data_small.to_pickle('input/reuters_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small.to_json('input/reuters_small.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load small\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 8 zip example-table to pickle\n",
    "data_small.to_pickle('input/reuters_small8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save large table to pickle\n",
    "data.to_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load large\n",
    "reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read new unseen data: XML / ZIP, preprocess it and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reading of itemid:  <newsitem itemid=\"807582\" ..>\n",
    "def read_one_zipfile_newsid(filepath):  \n",
    "    '''\n",
    "    read and parse contents of single zipfile (with about 100+ xml-files in it)\n",
    "    fields: headline, text, classes\n",
    "    return them as list\n",
    "    '''\n",
    "    this_documents=[]\n",
    "    \n",
    "    zf = zipfile.ZipFile(filepath, 'r')    \n",
    "\n",
    "    # for all xml-files within a zip\n",
    "    for name in zf.namelist():\n",
    "        #if name.endswith('xml'): continue\n",
    "    \n",
    "        infile = zf.open(name)    \n",
    "        contents = infile.read()\n",
    "        soup = BeautifulSoup(contents,'lxml')\n",
    "    \n",
    "        headline = soup.find('headline')\n",
    "        text = soup.find('text')       #print(headline.get_text())\n",
    "        \n",
    "        ### ADD READING OF NEWSITEM ID\n",
    "        # Get newsid - number of article\n",
    "        newsid = ''\n",
    "        hrefs = soup.find_all('newsitem')\n",
    "        for href in hrefs:\n",
    "            #print(href.get('itemid'))\n",
    "            newsid=href.get('itemid')        \n",
    "    \n",
    "    # extract all topic-classes \n",
    "    # only take \"codes\" by topic, not region or industry: class == 'bip:topics:1.0'\n",
    "        classcodes = []\n",
    "        for element in soup.find_all('codes', class_='bip:topics:1.0'):\n",
    "            for code in element.find_all('code'):\n",
    "                clas = code['code']\n",
    "                #print(clas)\n",
    "                classcodes.append(clas)\n",
    "\n",
    "        this_documents.append({'newsid': newsid, 'headline': headline.get_text(), 'text': text.get_text(), 'codes': classcodes})\n",
    "    return this_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['19970410-test.zip', '19970619-test.zip', '19970719-test.zip', '19970510-test.zip']\n"
     ]
    }
   ],
   "source": [
    "# get list of *.zip files in dir, such that contain xml-files (name starts with 1).\n",
    "dirpath = 'test_data/'\n",
    "files = [f for f in os.listdir(dirpath) if os.path.isfile(os.path.join(dirpath, f))]\n",
    "# cut out codes.zip, readme.txt etc. All zips containing .xml start with 1\n",
    "# NOTICE - in new_data, all zips contain 19, also one extra html contain only 1\n",
    "filenames_zip = [f for f in files if '19' in f]\n",
    "print(len(filenames_zip))\n",
    "print(filenames_zip[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19970410-test.zip',\n",
       " '19970619-test.zip',\n",
       " '19970719-test.zip',\n",
       " '19970510-test.zip',\n",
       " '19970629-test.zip',\n",
       " '19970729-test.zip',\n",
       " '19970520-test.zip',\n",
       " '19970818-test.zip',\n",
       " '19970430-test.zip',\n",
       " '19970530-test.zip',\n",
       " '19970709-test.zip',\n",
       " '19970609-test.zip',\n",
       " '19970808-test.zip',\n",
       " '19970420-test.zip']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_zip.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19970410-test.zip',\n",
       " '19970420-test.zip',\n",
       " '19970430-test.zip',\n",
       " '19970510-test.zip',\n",
       " '19970520-test.zip',\n",
       " '19970530-test.zip',\n",
       " '19970609-test.zip',\n",
       " '19970619-test.zip',\n",
       " '19970629-test.zip',\n",
       " '19970709-test.zip',\n",
       " '19970719-test.zip',\n",
       " '19970729-test.zip',\n",
       " '19970808-test.zip',\n",
       " '19970818-test.zip']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33142"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all zipfiles\n",
    "mypath = 'test_data/'\n",
    "documents= []\n",
    "\n",
    "ind_8 = 0\n",
    "for i, file in enumerate(filenames_zip):\n",
    "    if i == 8:\n",
    "        ind_8 = len(documents)\n",
    "    documents.extend( read_one_zipfile_newsid(mypath+file) )\n",
    "len(documents)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>newsid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>PRESS DIGEST - SOUTH AFRICA - APRIL 10.</td>\n",
       "      <td>498646</td>\n",
       "      <td>\\nThese are the leading stories in the South A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...</td>\n",
       "      <td>498647</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...</td>\n",
       "      <td>498648</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...</td>\n",
       "      <td>498649</td>\n",
       "      <td>\\n*\\nMinutes of the sitting of Wednesday, 29 J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Toronto stocks close easier in lackluster deal...</td>\n",
       "      <td>498650</td>\n",
       "      <td>\\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>Intensity, Renata in merger deal.</td>\n",
       "      <td>498651</td>\n",
       "      <td>\\nA hostile takeover in Canada's oil patch tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>WIC seen cutting jobs as TV battle looms.</td>\n",
       "      <td>498652</td>\n",
       "      <td>\\nThe board of WIC Western International Commu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>FOCUS-Nortel, Williams to combine sales arms.</td>\n",
       "      <td>498653</td>\n",
       "      <td>\\nWilliams Communications Group Inc. and North...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[]</td>\n",
       "      <td>Canada edges toward June federal election.</td>\n",
       "      <td>498654</td>\n",
       "      <td>\\nIt is just about as official as you can get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>Canada board approves Federated pipeline project.</td>\n",
       "      <td>498655</td>\n",
       "      <td>\\nCanada's National Energy Board said on Thurs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codes                                           headline  newsid  \\\n",
       "0    []            PRESS DIGEST - SOUTH AFRICA - APRIL 10.  498646   \n",
       "1    []  OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...  498647   \n",
       "2    []  OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...  498648   \n",
       "3    []  OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...  498649   \n",
       "4    []  Toronto stocks close easier in lackluster deal...  498650   \n",
       "5    []                  Intensity, Renata in merger deal.  498651   \n",
       "6    []          WIC seen cutting jobs as TV battle looms.  498652   \n",
       "7    []      FOCUS-Nortel, Williams to combine sales arms.  498653   \n",
       "8    []         Canada edges toward June federal election.  498654   \n",
       "9    []  Canada board approves Federated pipeline project.  498655   \n",
       "\n",
       "                                                text  \n",
       "0  \\nThese are the leading stories in the South A...  \n",
       "1  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "3  \\n*\\nMinutes of the sitting of Wednesday, 29 J...  \n",
       "4  \\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...  \n",
       "5  \\nA hostile takeover in Canada's oil patch tur...  \n",
       "6  \\nThe board of WIC Western International Commu...  \n",
       "7  \\nWilliams Communications Group Inc. and North...  \n",
       "8  \\nIt is just about as official as you can get ...  \n",
       "9  \\nCanada's National Energy Board said on Thurs...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame(documents)\n",
    "new_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.sort_values('newsid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>newsid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>PRESS DIGEST - SOUTH AFRICA - APRIL 10.</td>\n",
       "      <td>498646</td>\n",
       "      <td>\\nThese are the leading stories in the South A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...</td>\n",
       "      <td>498647</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...</td>\n",
       "      <td>498648</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...</td>\n",
       "      <td>498649</td>\n",
       "      <td>\\n*\\nMinutes of the sitting of Wednesday, 29 J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Toronto stocks close easier in lackluster deal...</td>\n",
       "      <td>498650</td>\n",
       "      <td>\\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>Intensity, Renata in merger deal.</td>\n",
       "      <td>498651</td>\n",
       "      <td>\\nA hostile takeover in Canada's oil patch tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>WIC seen cutting jobs as TV battle looms.</td>\n",
       "      <td>498652</td>\n",
       "      <td>\\nThe board of WIC Western International Commu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>FOCUS-Nortel, Williams to combine sales arms.</td>\n",
       "      <td>498653</td>\n",
       "      <td>\\nWilliams Communications Group Inc. and North...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[]</td>\n",
       "      <td>Canada edges toward June federal election.</td>\n",
       "      <td>498654</td>\n",
       "      <td>\\nIt is just about as official as you can get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>Canada board approves Federated pipeline project.</td>\n",
       "      <td>498655</td>\n",
       "      <td>\\nCanada's National Energy Board said on Thurs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codes                                           headline  newsid  \\\n",
       "0    []            PRESS DIGEST - SOUTH AFRICA - APRIL 10.  498646   \n",
       "1    []  OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...  498647   \n",
       "2    []  OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...  498648   \n",
       "3    []  OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...  498649   \n",
       "4    []  Toronto stocks close easier in lackluster deal...  498650   \n",
       "5    []                  Intensity, Renata in merger deal.  498651   \n",
       "6    []          WIC seen cutting jobs as TV battle looms.  498652   \n",
       "7    []      FOCUS-Nortel, Williams to combine sales arms.  498653   \n",
       "8    []         Canada edges toward June federal election.  498654   \n",
       "9    []  Canada board approves Federated pipeline project.  498655   \n",
       "\n",
       "                                                text  \n",
       "0  \\nThese are the leading stories in the South A...  \n",
       "1  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "3  \\n*\\nMinutes of the sitting of Wednesday, 29 J...  \n",
       "4  \\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...  \n",
       "5  \\nA hostile takeover in Canada's oil patch tur...  \n",
       "6  \\nThe board of WIC Western International Commu...  \n",
       "7  \\nWilliams Communications Group Inc. and North...  \n",
       "8  \\nIt is just about as official as you can get ...  \n",
       "9  \\nCanada's National Energy Board said on Thurs...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "new_data.to_pickle('input/data_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codes                                                      []\n",
       "headline              PRESS DIGEST - SOUTH AFRICA - APRIL 10.\n",
       "newsid                                                 498646\n",
       "text        \\nThese are the leading stories in the South A...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
