{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read data - short version 3400+ documents\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# OR 8xsmall size\n",
    "reuters = pd.read_pickle('input/reuters_small8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR load full data, if produced. 435 MB. NOT in Github currently. \n",
    "# You can produce this in about 30 min with preprocess_data.ipynb\n",
    "reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text  \n",
       "0  \\nEureko, an alliance of six European financia...  \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# read classcodes\n",
    "classcodes= pd.read_csv('input/classcodes.csv')\n",
    "print(len(classcodes))\n",
    "#classcodes[0:12]\n",
    "\n",
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()\n",
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "reuters['codes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "reuters[0:3]\n",
    "# Multihot, for single list - one row\n",
    "def multihot(tags):\n",
    "    return [1 if tag in tags else 0 for tag in taglist]\n",
    "\n",
    "# list of classes, 126 int: [0...125]\n",
    "taglist = list(classcodes.index)\n",
    "Y_hot = [multihot(claslist) for claslist in reuters.codes]\n",
    "reuters['codes'] = Y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text  \n",
       "0  \\nEureko, an alliance of six European financia...  \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in:\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Fields\n",
    "TEXT = data.Field()\n",
    "HEADLINE = data.Field()\n",
    "LABELS = data.LabelField(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in random order\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "idx = np.random.permutation(len(reuters))\n",
    "reuters = reuters.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it\n",
    "size = len(reuters)\n",
    "train_size = int(0.7*size)\n",
    "test_size = int(0.85*size)\n",
    "# val is rest\n",
    "\n",
    "train = reuters[0: train_size]\n",
    "val = reuters[train_size : test_size]\n",
    "test = reuters[test_size : size]\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For final training only: use all training data\n",
    "dev/test sets are now part of same training data, so they will show too high score.\n",
    "Stop training at same nr epochs found good with separete train/dev/set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For final training only, use all data\n",
    "# split it\n",
    "size = len(reuters)\n",
    "\n",
    "# After finding model, higher training data, run same nr of epochs\n",
    "#train_size = int(0.95*size)\n",
    "train_size = size # use all data, will overfit dev set but its ok\n",
    "test_size = int(0.97*size)\n",
    "# val is rest\n",
    "\n",
    "train = reuters[0: train_size]\n",
    "#val = reuters[train_size : test_size]\n",
    "val = reuters[test_size : size]\n",
    "test = reuters[test_size : size] # same as val, not needed\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7f135bb027b8>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7f135bb027f0>),\n",
       " 'codes': ('l', <torchtext.data.field.LabelField at 0x7f135bb026d8>)}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell torchText which Fields to apply to which json elements\n",
    "fields = {'headline': ('h', HEADLINE), 'text': ('t', TEXT), 'codes': ('l', LABELS)}\n",
    "fields"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import dill as pickle\n",
    "pickle.dump(fields, open('fields_t.pkl', 'wb'))\n",
    "# TypeError: can't pickle torch.dtype objects - Known problem while saing Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (TabularDataset)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'input',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'val.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 50])\n"
     ]
    }
   ],
   "source": [
    "# GLOVE\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.50d\")\n",
    "HEADLINE.build_vocab(train)\n",
    "LABELS.build_vocab(train)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 299773\n",
      "Number of validation examples: 8994\n",
      "Number of testing examples: 8994\n",
      "------------\n",
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABELS vocabulary: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print('------------')\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABELS vocabulary: {len(LABELS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3112856), ('of', 1664693), ('to', 1661936), ('in', 1321409), ('a', 1238399), ('and', 1238227), ('on', 762926), ('said', 591160), ('for', 579301), ('The', 491337)]\n",
      "-----\n",
      "['<unk>', '<pad>', 'the', 'of', 'to', 'in', 'a', 'and', 'on', 'said']\n",
      "defaultdict(<function _default_unk_index at 0x7f14b7dc5d08>, {'codes': 0, 'headline': 1, 'text': 2})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))\n",
    "print('-----')\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABELS.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be ranked according to the highest micro-averaged F1 score. \n",
    "This will be calculated using the f1_score function found in scikit-learn, using a command like \n",
    "f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred \n",
    "the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document\n",
    "i contains the label j.\n",
    "\n",
    "Scikit:  Micro-average in F1-score\n",
    " \n",
    "'micro':\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score for BATCH\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns f1 accuracy from sklearn\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    #rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    preds_cpu = rounded_preds.cpu().data.numpy()\n",
    "    y_cpu = y.cpu().data.numpy()\n",
    "    f1 = f1_score(y_cpu, preds_cpu, average='micro')\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_own_accuracy(preds, y):\n",
    "    '''for micro-average\n",
    "    Returns counts of true_pos, false_pos and false_negative.\n",
    "    For counting precision, recall and F1 globally\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    '''\n",
    "    #round predictions to the closest integer\n",
    "    #rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    preds = rounded_preds.cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "        \n",
    "    # True positive\n",
    "    tpos = np.sum(np.logical_and(preds == 1, y == 1))\n",
    " \n",
    "    # True negative\n",
    "    #tneg = np.sum(np.logical_and(preds == 0, y == 0))\n",
    " \n",
    "    # False positive\n",
    "    fpos = np.sum(np.logical_and(preds == 1, y == 0))\n",
    " \n",
    "    # False negative\n",
    "    fneg = np.sum(np.logical_and(preds == 0, y == 1))\n",
    "\n",
    "    return tpos, fpos, fneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    #rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        if batch.t.shape[1] != BATCH_SIZE:\n",
    "              continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(torch.cat((batch.t, batch.h))).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l.float())\n",
    "        \n",
    "        tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "        epoch_tpos += tpos\n",
    "        epoch_fpos += fpos\n",
    "        epoch_fneg += fneg\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "    \n",
    "    # Counted f1-score is Micro-average version\n",
    "    # avoid div by zero with epsilon. \n",
    "    # F1 for 0 - no labels is not defined, but here we give it score 1\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps )\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +2*eps))\n",
    "    \n",
    "    # zero true_positive can cause F1=1, (because only 2*(epsilon / 2epsilon) remains, leading to 1)\n",
    "    # fix it to zero\n",
    "    if (epoch_precision==0 and epoch_recall==0):\n",
    "        epoch_f1 = 0\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            if batch.t.shape[1] != BATCH_SIZE:\n",
    "                continue\n",
    "\n",
    "            predictions = model(torch.cat((batch.t, batch.h))).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l.float())\n",
    "            \n",
    "            tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "            epoch_tpos += tpos\n",
    "            epoch_fpos += fpos\n",
    "            epoch_fneg += fneg            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            #epoch_acc += acc.item()\n",
    "\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +2*eps))          \n",
    "    \n",
    "    # zero true_positive can cause F1=1, (because only 2*(epsilon / 2epsilon) remains, leading to 1)\n",
    "    # fix it to zero\n",
    "    if (epoch_precision==0 and epoch_recall==0):\n",
    "        epoch_f1 = 0\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, iterator):\n",
    "        \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            #if batch.t.shape[1] != BATCH_SIZE:\n",
    "            #    continue\n",
    "\n",
    "            predictions = model(torch.cat((batch.t, batch.h))).squeeze(1)\n",
    "            predictions = torch.round(predictions)\n",
    "            \n",
    "            cpu_pred = predictions.cpu()\n",
    "            result = cpu_pred.data.numpy()            \n",
    "            # unpack the #batch nr of predictions and add individually\n",
    "            for item in result:\n",
    "                preds.append(item)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "INPUT_DIM = len(TEXT.vocab) # 25002\n",
    "EMBEDDING_DIM = 50\n",
    "OUTPUT_DIM = 126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models to try\n",
    "\n",
    "Add wanted models to list, then train them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place to put model definitions\n",
    "try_models = []\n",
    "try_descs = []\n",
    "try_epochs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN with high nr of filters\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,5,7]\n",
    "DROPOUT = 0.5\n",
    "N_EPOCHS = 6 # full data, try 6\n",
    "#N_EPOCHS = 1 # temporary\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "# 14 epochs gave f1 0.84\n",
    "desc = \"CNN 300x3,5,7 filters\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CNN 1\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "DROPOUT = 0.5\n",
    "N_EPOCHS = 60 #60 enough for small-data\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "desc = \"CNN 100x3,4,5 channel\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CNN 2\n",
    "N_FILTERS = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "DROPOUT = 0.5\n",
    "N_EPOCHS = 60\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "# 14 epochs gave f1 0.84\n",
    "desc = \"CNN 200x3,5,7 channel\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#LSTM 1\n",
    "HIDDEN_DIM = 100\n",
    "N_EPOCHS = 200\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "model = models.LSTMv2(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, BIDIRECTIONAL, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "desc = \"LSTM 100hidden 1-layer\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#LSTM 1b - 2-layer\n",
    "HIDDEN_DIM = 100\n",
    "N_EPOCHS = 200\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "model = models.LSTMv2(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, BIDIRECTIONAL, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "desc = \"LSTM 100hidden 2-layer\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# LSTM 2\n",
    "HIDDEN_DIM = 250\n",
    "N_EPOCHS = 350 # small data\n",
    "N_EPOCHS = 15 # try, full data\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "model = models.LSTM(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, BIDIRECTIONAL, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "#model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "desc = \"LSTM 250hidden 1-layer\"\n",
    "\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# LSTM-CNN\n",
    "N_FILTERS = 200\n",
    "HIDDEN_DIM = 100\n",
    "FILTER_SIZES = [3,5,7]\n",
    "N_EPOCHS=100\n",
    "\n",
    "model = models.LSTM_CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, HIDDEN_DIM, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "desc = \"LSTM + CNN\"\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CNN-LSTM\n",
    "HIDDEN_DIM = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "N_FILTERS = 150\n",
    "#N_EPOCHS= 300 # small data\n",
    "N_EPOCHS= 15 # try, full data\n",
    "\n",
    "model = models.CNN_LSTM(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, HIDDEN_DIM, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "desc = \"CNN 100x3,5,7 filter + LSTM 100hidden\"\n",
    "try_models.append(model)\n",
    "try_descs.append(desc)\n",
    "try_epochs.append(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# COMMON\n",
    "model = model.to(device)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-2, betas=(0.9, 0.99))\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCELoss()\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Reset \n",
    "train_losses=[]\n",
    "train_f1s=[]\n",
    "val_losses=[]\n",
    "val_f1s=[]\n",
    "times=[]\n",
    "\n",
    "# If want repeatability\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "def init_models():\n",
    "    ''' init global parameters'''\n",
    "    global model\n",
    "    global optimizer\n",
    "    global criterion\n",
    "    global train_losses\n",
    "    global train_f1s\n",
    "    global val_losses\n",
    "    global val_f1s\n",
    "    global times\n",
    "    global SEED\n",
    "    global torch\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # Reset \n",
    "    train_losses=[]\n",
    "    train_f1s=[]\n",
    "    val_losses=[]\n",
    "    val_f1s=[]\n",
    "    times=[]\n",
    "\n",
    "    # If want repeatability\n",
    "    SEED = 1\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    \n",
    "    # Faster\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer # default Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN 300x3,5,7 filters']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_descs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: CNN 300x3,5,7 filters\n",
      "| Ep:01 |Tr Loss:0.035 |Prec:0.857 |Rec:0.662 |f1:0.747 |Val Loss:0.026 |prec:0.836 |rec:0.829 |f1:0.833 |\n",
      "| Ep:02 |Tr Loss:0.025 |Prec:0.882 |Rec:0.762 |f1:0.818 |Val Loss:0.025 |prec:0.836 |rec:0.864 |f1:0.850 |\n",
      "| Ep:03 |Tr Loss:0.024 |Prec:0.888 |Rec:0.783 |f1:0.832 |Val Loss:0.022 |prec:0.862 |rec:0.865 |f1:0.864 |\n",
      "| Ep:04 |Tr Loss:0.022 |Prec:0.893 |Rec:0.795 |f1:0.841 |Val Loss:0.021 |prec:0.869 |rec:0.876 |f1:0.872 |\n",
      "| Ep:05 |Tr Loss:0.021 |Prec:0.897 |Rec:0.803 |f1:0.847 |Val Loss:0.020 |prec:0.870 |rec:0.885 |f1:0.877 |\n",
      "| Ep:06 |Tr Loss:0.021 |Prec:0.899 |Rec:0.811 |f1:0.853 |Val Loss:0.018 |prec:0.888 |rec:0.882 |f1:0.885 |\n",
      "| Test Loss: 0.018 ||Prec:0.888 |Rec:0.882 |Test F1: 0.885 |\n",
      " \n",
      " Total time used for training: 2698.9966175556183 s ##########\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Store results of training\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(len(try_models)):\n",
    "    \n",
    "    model = try_models[i]\n",
    "    desc = try_descs[i]\n",
    "    epochs = try_epochs[i]\n",
    "    print(f'Training model: {desc}')\n",
    "\n",
    "    # init global parameters\n",
    "    init_models()\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    #N_EPOCHS = 3\n",
    "    N_EPOCHS = epochs\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "        end = time.time(); elapsed = end-start\n",
    "    \n",
    "        valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "        times.append(elapsed) \n",
    "        train_losses.append(train_loss); train_f1s.append(train_f1)\n",
    "        val_losses.append(valid_loss); val_f1s.append(valid_f1)\n",
    "    \n",
    "        print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        \n",
    "\n",
    "\n",
    "    #Test F1-score\n",
    "    test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "    print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Test F1:{test_f1: .3f} |')        \n",
    "        \n",
    "    # Store results\n",
    "    times_cumul = pd.Series(times).cumsum() # cumulative time    \n",
    "    results = results.append({'Model': model_name,\n",
    "                          'Desc' : desc,\n",
    "                          'Test_f1': test_f1,\n",
    "                          'Time': times_cumul,\n",
    "                          'Train_loss': pd.DataFrame({'Train_loss':train_losses}), \n",
    "                          'Train_f1': pd.DataFrame({'Train_f1':train_f1s}), \n",
    "                          'Val_loss': pd.DataFrame({'Val_loss':val_losses}), \n",
    "                          'Val_f1': pd.DataFrame({'Val_f1':val_f1s}),\n",
    "                                         }, ignore_index=True)\n",
    "\n",
    "    print(\" \")\n",
    "    print(f\" Total time used for training: {sum(times)} s ##########\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desc</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test_f1</th>\n",
       "      <th>Time</th>\n",
       "      <th>Train_f1</th>\n",
       "      <th>Train_loss</th>\n",
       "      <th>Val_f1</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN 300x3,5,7 filters</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>0    409.784567\n",
       "dtype: float64</td>\n",
       "      <td>Train_f1\n",
       "0  0.740232</td>\n",
       "      <td>Train_loss\n",
       "0    0.035656</td>\n",
       "      <td>Val_f1\n",
       "0  0.816793</td>\n",
       "      <td>Val_loss\n",
       "0  0.028992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Desc Model   Test_f1                            Time  \\\n",
       "0  CNN 300x3,5,7 filters  CNN2  0.819805  0    409.784567\n",
       "dtype: float64   \n",
       "\n",
       "                  Train_f1                   Train_loss  \\\n",
       "0     Train_f1\n",
       "0  0.740232     Train_loss\n",
       "0    0.035656   \n",
       "\n",
       "                    Val_f1                 Val_loss  \n",
       "0       Val_f1\n",
       "0  0.816793     Val_loss\n",
       "0  0.028992  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training results - score and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190106-1350\n"
     ]
    }
   ],
   "source": [
    "datetime_string = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "print(datetime_string)\n",
    "results.to_pickle('model_results/results_CNN_all_traindata'+datetime_string+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this version create the model object with same paramters as when training. Then load weights.\n",
    "This version saves also gradients etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/model_DICT_CNN300_f1_all_traindata_0_853_train.pt')\n",
    "#torch.save(model, 'filename.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole model\n",
    "torch.save(model, 'models/model_WHOLE_CNN300_f1_all_traindata_0_853_train.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Whole model\n",
    "model = torch.load('models/model_WHOLE_CNN300_f1_all_traindata_0_853_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only Dict / weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE same creation as when model was trained\n",
    "#model2 = RNN(input_dim=25002, embedding_dim=50, hidden_dim=256, output_dim=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_DICT_CNN300_f1_all_traindata_0_853_train.pt'))                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN2(\n",
       "  (embedding): Embedding(25002, 50)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 300, kernel_size=(3, 50), stride=(1, 1))\n",
       "    (1): Conv2d(1, 300, kernel_size=(5, 50), stride=(1, 1))\n",
       "    (2): Conv2d(1, 300, kernel_size=(7, 50), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=900, out_features=126, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN2(\n",
       "  (embedding): Embedding(25002, 50)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 300, kernel_size=(3, 50), stride=(1, 1))\n",
       "    (1): Conv2d(1, 300, kernel_size=(5, 50), stride=(1, 1))\n",
       "    (2): Conv2d(1, 300, kernel_size=(7, 50), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=900, out_features=126, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.018 ||Prec:0.888 |Rec:0.882 |Test F1: 0.885 |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Test F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional -  Extra test using training sets test-data in place of new data, so we have known labels to confirm result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data dataset\n",
    "new_dataset1 = data.TabularDataset(\n",
    "                                        path = 'input/test.json',\n",
    "                                        format = 'json',\n",
    "                                        #fields = fields_predict\n",
    "                                        fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Zimbabwe',\n",
       " 'dollar',\n",
       " 'was',\n",
       " 'quoted',\n",
       " 'steady',\n",
       " 'on',\n",
       " 'the',\n",
       " 'U.S.',\n",
       " 'dollar']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out example\n",
    "ex = new_dataset[1]\n",
    "ex.t[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZIMBABWE', 'DOLLAR', 'STARTS', 'MONDAY', 'STABLE', 'TO', 'WEAKER.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out example\n",
    "ex.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_iterator1 = data.Iterator(\n",
    "    dataset=new_dataset1, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t),\n",
    "    train=False,\n",
    "    sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, new_iterator1)\n",
    "\n",
    "# moved inside predict()\n",
    "#rounded_preds = torch.round(preds)   \n",
    "#preds_cpu = rounded_preds.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = predict(model, new_iterator)\n",
    "\n",
    "# turn into binary\n",
    "for i in range(len(preds)):\n",
    "    preds[i]= torch.round(preds[i])\n",
    "    \n",
    "# move from GPU (torch tensor) to CPU\n",
    "for i in range(len(preds)):\n",
    "    preds[i]= preds[i].cpu().data.numpy()\n",
    "    \n",
    "# list of arrays to 2-dim numpy array\n",
    "preds_np = np.array(preds)\n",
    "\n",
    "# Not needed:\n",
    "# to Pandas DataFrame\n",
    "#preds_pd = pd.DataFrame(preds_np)\n",
    "# floats to int\n",
    "#preds_pd = preds_pd.astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pd = pd.DataFrame(preds)\n",
    "preds_pd.to_csv('output/predictions_trainset_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('input/test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth, from pandas DataFrame\n",
    "# Each is a 126 item list in a DataFrame\n",
    "# Trun into 2-dim np.array\n",
    "\n",
    "# explode the list into columns\n",
    "temp = test['codes'].apply(pd.Series)\n",
    "# turn to np.array\n",
    "y_true = np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16082617373947755"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_true,\n",
    "         preds,\n",
    "         average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.018 ||Prec:0.888 |Rec:0.882 |Test F1: 0.885 |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, new_iterator1, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Test F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33142"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it on final test data\n",
    "new_data = reuters = pd.read_pickle('input/data_new.pkl')\n",
    "new_data.to_json('input/new_data.json', orient='records', lines=True)\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_json('input/new_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>PRESS DIGEST - SOUTH AFRICA - APRIL 10.</td>\n",
       "      <td>\\nThese are the leading stories in the South A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...</td>\n",
       "      <td>\\n*\\nMinutes of the sitting of Wednesday, 29 J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Toronto stocks close easier in lackluster deal...</td>\n",
       "      <td>\\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codes                                           headline  \\\n",
       "0    []            PRESS DIGEST - SOUTH AFRICA - APRIL 10.   \n",
       "1    []  OFFICIAL JOURNAL CONTENTS - OJ C 110 OF APRIL ...   \n",
       "2    []  OFFICIAL JOURNAL CONTENTS - OJ L 94 OF APRIL 9...   \n",
       "3    []  OFFICIAL JOURNAL CONTENTS - OJ C 55 OF FEBRUAR...   \n",
       "4    []  Toronto stocks close easier in lackluster deal...   \n",
       "\n",
       "                                                text  \n",
       "0  \\nThese are the leading stories in the South A...  \n",
       "1  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...  \n",
       "3  \\n*\\nMinutes of the sitting of Wednesday, 29 J...  \n",
       "4  \\nCHANGE\\t\\t\\t\\t    CHANGE\\nTSE\\t  5790.11    ...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7f135bb027b8>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7f135bb027f0>)}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields_predict = {'headline': ('h', HEADLINE), 'text': ('t', TEXT)} # 'codes': ('l', LABELS)\n",
    "fields_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data dataset\n",
    "new_dataset = data.TabularDataset(\n",
    "                                        path = 'input/new_data.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields_predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_iterator = data.Iterator(\n",
    "    dataset=new_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t),\n",
    "    train=False,\n",
    "    sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, new_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.asarray(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pd = pd.DataFrame(preds)\n",
    "# floats to int\n",
    "preds_pd = preds_pd.astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime_string = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "#print(datetime_string)\n",
    "preds_pd.to_csv('output/predictions_newdata_fulltraindata_CNN.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = predict(model, new_iterator)\n",
    "\n",
    "# turn into binary\n",
    "for i in range(len(preds)):\n",
    "    preds[i]= torch.round(preds[i])\n",
    "    \n",
    "# move from GPU (torch tensor) to CPU\n",
    "for i in range(len(preds)):\n",
    "    preds[i]= preds[i].cpu().data.numpy()\n",
    "    \n",
    "# list of arrays to 2-dim numpy array\n",
    "preds_np = np.array(preds)\n",
    "\n",
    "# to Pandas DataFrame\n",
    "preds_pd = pd.DataFrame(preds_np)\n",
    "\n",
    "# floats to int\n",
    "preds_pd = preds_pd.astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   116  117  118  119  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    1   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   120  121  122  123  124  125  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    1    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_string = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "print(datetime_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pd.to_csv('output/predictions'+datetime_string+'.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
