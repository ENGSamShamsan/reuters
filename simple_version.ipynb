{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data - short version 3400+ documents\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24247\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text       classes  \n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]  \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8x small size\n",
    "reuters = pd.read_pickle('input/reuters_small8.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full data, if produced. 435 MB. NOT in Github currently. \n",
    "# You can produce this in about 30 min with preprocess_data.ipynb\n",
    "\n",
    "reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# read classcodes\n",
    "classcodes= pd.read_csv('input/classcodes.csv')\n",
    "print(len(classcodes))\n",
    "#classcodes[0:12]\n",
    "\n",
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()\n",
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "reuters['codes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "reuters[0:3]\n",
    "# Multihot, for single list - one row\n",
    "def multihot(tags):\n",
    "    return [1 if tag in tags else 0 for tag in taglist]\n",
    "\n",
    "# list of classes, 126 int: [0...125]\n",
    "taglist = list(classcodes.index)\n",
    "Y_hot = [multihot(claslist) for claslist in reuters.codes]\n",
    "reuters['codes'] = Y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2  Official Journal contents - OJ L 190 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in:\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Fields\n",
    "TEXT = data.Field()\n",
    "HEADLINE = data.Field()\n",
    "\n",
    "LABELS = data.LabelField(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in random order\n",
    "idx = np.random.permutation(len(reuters))\n",
    "reuters = reuters.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it\n",
    "size = len(reuters)\n",
    "train_size = int(0.7*size)\n",
    "test_size = int(0.85*size)\n",
    "\n",
    "train = reuters[0: train_size]\n",
    "val = reuters[train_size : test_size]\n",
    "test = reuters[test_size : size]\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7f8ec70182b0>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7f8ec7018198>),\n",
       " 'codes': ('l', <torchtext.data.field.LabelField at 0x7f8ec7018320>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell torchText which Fields to apply to which json elements\n",
    "\n",
    "fields = {'headline': ('h', HEADLINE), 'text': ('t', TEXT), 'codes': ('l', LABELS)}\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (TabularDataset)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'input',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'val.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")\n",
    "# test\n",
    "#print(vars(train_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 50])\n"
     ]
    }
   ],
   "source": [
    "# GLOVE\n",
    "\n",
    "#TEXT.build_vocab(train)\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.50d\")\n",
    "HEADLINE.build_vocab(train)\n",
    "LABELS.build_vocab(train)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2398\n",
      "Number of validation examples: 514\n",
      "Number of testing examples: 514\n",
      "------------\n",
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABELS vocabulary: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print('------------')\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABELS vocabulary: {len(LABELS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 22500), ('of', 12430), ('to', 11882), ('in', 9658), ('and', 9178), ('a', 8790), ('on', 5732), ('said', 4431), ('for', 4175), ('The', 3585)]\n",
      "-----\n",
      "['<unk>', '<pad>', 'the', 'of', 'to', 'in', 'and', 'a', 'on', 'said']\n",
      "defaultdict(<function _default_unk_index at 0x7f8f28809268>, {'classes': 0, 'classes_pad': 1, 'codes': 2, 'headline': 3, 'text': 4})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))\n",
    "print('-----')\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABELS.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be ranked according to the highest micro-averaged F1 score. \n",
    "This will be calculated using the f1_score function found in scikit-learn, using a command like \n",
    "f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred \n",
    "the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document\n",
    "i contains the label j.\n",
    "\n",
    "Scikit:  Micro-average in F1-score\n",
    " \n",
    "'micro':\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score for BATCH\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns f1 accuracy from sklearn\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds_cpu = rounded_preds.cpu().data.numpy()\n",
    "    y_cpu = y.cpu().data.numpy()\n",
    "    f1 = f1_score(y_cpu, preds_cpu, average='micro')\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_own_accuracy(preds, y):\n",
    "    '''Returns counts of true_pos, false_pos and false_negative.\n",
    "    For counting precision, recall and F1 globally\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    '''\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds = rounded_preds.cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "        \n",
    "    # True positive\n",
    "    tpos = np.sum(np.logical_and(preds == 1, y == 1))\n",
    " \n",
    "    # True negative\n",
    "    #tneg = np.sum(np.logical_and(preds == 0, y == 0))\n",
    " \n",
    "    # False positive\n",
    "    fpos = np.sum(np.logical_and(preds == 1, y == 0))\n",
    " \n",
    "    # False negative\n",
    "    fneg = np.sum(np.logical_and(preds == 0, y == 1))\n",
    "\n",
    "    return tpos, fpos, fneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.t).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l.float())\n",
    "        \n",
    "        tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "        epoch_tpos += tpos\n",
    "        epoch_fpos += fpos\n",
    "        epoch_fneg += fneg\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "    \n",
    "    # Counted f1-score is Micro-average version\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps )\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +eps))\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.t).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l.float())\n",
    "            \n",
    "            tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "            epoch_tpos += tpos\n",
    "            epoch_fpos += fpos\n",
    "            epoch_fneg += fneg            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            #epoch_acc += acc.item()\n",
    "\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +eps))            \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 126\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n",
    "        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        x = x.permute(1, 0)\n",
    "                \n",
    "        #x = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 126\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "N_FILTERS = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "OUTPUT_DIM = 126\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "# 14 epochs gave f1 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.040 |Prec:0.844 |Rec:0.608 |f1:0.707 |Val Loss:0.033 |prec:0.791 |rec:0.815 |f1:0.803 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.028 |Prec:0.876 |Rec:0.733 |f1:0.798 |Val Loss:0.031 |prec:0.798 |rec:0.844 |f1:0.820 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.025 |Prec:0.884 |Rec:0.760 |f1:0.817 |Val Loss:0.031 |prec:0.792 |rec:0.859 |f1:0.824 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.024 |Prec:0.890 |Rec:0.776 |f1:0.829 |Val Loss:0.029 |prec:0.809 |rec:0.856 |f1:0.832 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 4\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.023 |Prec:0.893 |Rec:0.787 |Tr f1:0.837 |Val prec:0.799 |Val rec:0.864 |Val f1:0.830 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.022 |Prec:0.897 |Rec:0.796 |Tr f1:0.843 |Val prec:0.798 |Val rec:0.866 |Val f1:0.831 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.021 |Prec:0.900 |Rec:0.804 |Tr f1:0.849 |Val prec:0.803 |Val rec:0.865 |Val f1:0.833 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.020 |Prec:0.903 |Rec:0.811 |Tr f1:0.855 |Val prec:0.810 |Val rec:0.862 |Val f1:0.835 |\n",
      "4\n",
      "| Ep:05 |Tr Loss:0.020 |Prec:0.905 |Rec:0.817 |Tr f1:0.859 |Val prec:0.821 |Val rec:0.855 |Val f1:0.838 |\n",
      "5\n",
      "| Ep:06 |Tr Loss:0.019 |Prec:0.908 |Rec:0.823 |Tr f1:0.863 |Val prec:0.831 |Val rec:0.851 |Val f1:0.841 |\n",
      "6\n",
      "| Ep:07 |Tr Loss:0.019 |Prec:0.910 |Rec:0.828 |Tr f1:0.867 |Val prec:0.834 |Val rec:0.849 |Val f1:0.841 |\n",
      "7\n",
      "| Ep:08 |Tr Loss:0.018 |Prec:0.912 |Rec:0.834 |Tr f1:0.871 |Val prec:0.838 |Val rec:0.848 |Val f1:0.843 |\n",
      "8\n",
      "| Ep:09 |Tr Loss:0.018 |Prec:0.914 |Rec:0.838 |Tr f1:0.874 |Val prec:0.844 |Val rec:0.844 |Val f1:0.844 |\n",
      "9\n",
      "| Ep:10 |Tr Loss:0.017 |Prec:0.915 |Rec:0.842 |Tr f1:0.877 |Val prec:0.841 |Val rec:0.847 |Val f1:0.844 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 10\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.017 |Prec:0.917 |Rec:0.846 |f1:0.880 |Val Loss:0.027 |prec:0.842 |rec:0.846 |f1:0.844 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this version create the model object with same paramters as when training. Then load weights.\n",
    "This version saves also gradients etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "#torch.save(model, 'filename.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN(input_dim=25002, embedding_dim=50, hidden_dim=256, output_dim=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('model.pkl'))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 50)\n",
       "  (rnn): RNN(50, 256)\n",
       "  (fc): Linear(in_features=256, out_features=126, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### easier but not so compatible\n",
    "This version does not save the gradients, only final model. \n",
    "Here you dont ened to create model object frist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'modelx.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = torch.load('modelx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.027 ||Prec:0.843 |Rec:0.845 |Test F1: 0.844 |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Test F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use final scoring \n",
    "\n",
    "The results will be ranked according to the highest micro-averaged F1 score. This will be calculated using the f1_score function found in scikit-learn, using a command like f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document i contains the label j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
