{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ C 221 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ C 220 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2        [G15, GCAT]  Official Journal contents - OJ L 190 of July 1...   \n",
       "3        [G15, GCAT]  Official Journal contents - OJ C 221 of July 1...   \n",
       "4        [G15, GCAT]  Official Journal contents - OJ C 220 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "3  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "4  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "3   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "4   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data - short version 3400+ documents\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full data, if produced. 435 MB. NOT in Github currently. \n",
    "# You can produce this in about 30 min with preprocess_data.ipynb\n",
    "\n",
    "#reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# read classcodes\n",
    "classcodes= pd.read_csv('input/classcodes.csv')\n",
    "print(len(classcodes))\n",
    "#classcodes[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()\n",
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "reuters['codes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "reuters[0:3]\n",
    "# Multihot, for single list - one row\n",
    "def multihot(tags):\n",
    "    return [1 if tag in tags else 0 for tag in taglist]\n",
    "\n",
    "# list of classes, 126 int: [0...125]\n",
    "taglist = list(classcodes.index)\n",
    "Y_hot = [multihot(claslist) for claslist in reuters.codes]\n",
    "reuters['codes'] = Y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 221 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 220 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2  Official Journal contents - OJ L 190 of July 1...   \n",
       "3  Official Journal contents - OJ C 221 of July 1...   \n",
       "4  Official Journal contents - OJ C 220 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "3  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "4  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "3   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "4   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in:\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Fields\n",
    "TEXT = data.Field()\n",
    "HEADLINE = data.Field()\n",
    "\n",
    "LABELS = data.LabelField(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test, save pd df to JSON\n",
    "                            # one record at time, one record by line\n",
    "reuters.to_json('input/reuters_small.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it\n",
    "train = reuters[0:2500]\n",
    "test = reuters[2500:3000]\n",
    "val = reuters[3000:len(reuters)]\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell torchText which Fields to apply to which json elements\n",
    "\n",
    "fields = {'headline': ('h', HEADLINE), 'text': ('t', TEXT), 'codes': ('l', LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7f0cedc87748>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7f0cedc87518>),\n",
       " 'codes': ('l', <torchtext.data.field.LabelField at 0x7f0cedc87550>)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (TabularDataset)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'input',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'val.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "#print(vars(train_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device('cpu')\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes=(16, 256, 256),\n",
    "    sort_key=lambda x: len(x.text), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without or with GLOVE\n",
    "\n",
    "#TEXT.build_vocab(train)\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.50d\")\n",
    "HEADLINE.build_vocab(train)\n",
    "LABELS.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7f0cb01060f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2500\n",
      "Number of validation examples: 426\n",
      "Number of testing examples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "LABELS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABELS vocabulary: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABELS vocabulary: {len(LABELS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 22529), ('of', 12791), ('to', 12004), ('and', 9792), ('in', 9599), ('a', 8831), ('on', 5491), ('said', 4417), ('for', 4282), ('The', 3677)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'of', 'to', 'and', 'in', 'a', 'on', 'said']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f0d4cee7d08>, {'classes': 0, 'classes_pad': 1, 'codes': 2, 'headline': 3, 'text': 4})\n"
     ]
    }
   ],
   "source": [
    "print(LABELS.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 126\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 50])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# OR\n",
    "#optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be ranked according to the highest micro-averaged F1 score. \n",
    "This will be calculated using the f1_score function found in scikit-learn, using a command like \n",
    "f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred \n",
    "the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document\n",
    "i contains the label j.\n",
    "\n",
    "Scikit:  Micro-average in F1-score\n",
    " \n",
    "'micro':\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score for BATCH\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns f1 accuracy from sklearn\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds_cpu = rounded_preds.cpu().data.numpy()\n",
    "    y_cpu = y.cpu().data.numpy()\n",
    "    f1 = f1_score(y_cpu, preds_cpu, average='micro')\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_own_accuracy(preds, y):\n",
    "    '''Returns counts of true_pos, false_pos and false_negative.\n",
    "    For counting precision, recall and F1 globally\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    '''\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds = rounded_preds.cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "        \n",
    "    # True positive\n",
    "    tpos = np.sum(np.logical_and(preds == 1, y == 1))\n",
    " \n",
    "    # True negative\n",
    "    #tneg = np.sum(np.logical_and(preds == 0, y == 0))\n",
    " \n",
    "    # False positive\n",
    "    fpos = np.sum(np.logical_and(preds == 1, y == 0))\n",
    " \n",
    "    # False negative\n",
    "    fneg = np.sum(np.logical_and(preds == 0, y == 1))\n",
    "\n",
    "    return tpos, fpos, fneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.t).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l.float())\n",
    "        \n",
    "        tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "        epoch_tpos += tpos\n",
    "        epoch_fpos += fpos\n",
    "        epoch_fneg += fneg\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "    \n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps )\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  (epoch_precision * epoch_recall) / (epoch_precision + epoch_recall +eps))\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.t).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l.float())\n",
    "            \n",
    "            tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "            epoch_tpos += tpos\n",
    "            epoch_fpos += fpos\n",
    "            epoch_fneg += fneg            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            #epoch_acc += acc.item()\n",
    "\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  (epoch_precision * epoch_recall) / (epoch_precision + epoch_recall +eps))            \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.696 |Prec:0.034 |Rec:0.743 |f1:0.065 |Val prec:0.030 |Val rec:0.708 |Val f1:0.058 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.696 |Prec:0.034 |Rec:0.742 |f1:0.065 |Val prec:0.030 |Val rec:0.706 |Val f1:0.058 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.695 |Prec:0.034 |Rec:0.729 |f1:0.065 |Val prec:0.031 |Val rec:0.700 |Val f1:0.059 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.695 |Prec:0.035 |Rec:0.720 |f1:0.066 |Val prec:0.032 |Val rec:0.699 |Val f1:0.060 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 4\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val prec:{valid_precision:.3f} |Val rec:{valid_recall:.3f} |Val f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some instability in training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeWarning: invalid value encountered in long_scalars\n",
    "# showing zeros\n",
    "# Ep:01 |Tr Loss:0.319 |Prec:nan |Rec:0.000 |Tr f1:nan |Val prec:nan |Val rec:0.000 |Val f1:nan |\n",
    "\n",
    "# Likely this was cause by F1s div by zero, when item or batch has 0 labels\n",
    "# Now epsilon added to train / eval, no more error but resulting values still sometimes go to zero.\n",
    "# seems like it would regain  and go to f1 0.247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.126 |Prec:0.511 |Rec:0.156 |Tr f1:0.239 |Val prec:0.496 |Val rec:0.163 |Val f1:0.246 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.124 |Prec:0.511 |Rec:0.156 |Tr f1:0.239 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.121 |Prec:0.511 |Rec:0.156 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.120 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "4\n",
      "| Ep:05 |Tr Loss:0.118 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "5\n",
      "| Ep:06 |Tr Loss:0.117 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "6\n",
      "| Ep:07 |Tr Loss:0.115 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "7\n",
      "| Ep:08 |Tr Loss:0.114 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "8\n",
      "| Ep:09 |Tr Loss:0.112 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "9\n",
      "| Ep:10 |Tr Loss:0.112 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "10\n",
      "| Ep:11 |Tr Loss:0.110 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "11\n",
      "| Ep:12 |Tr Loss:0.109 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "12\n",
      "| Ep:13 |Tr Loss:0.108 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "13\n",
      "| Ep:14 |Tr Loss:0.107 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "14\n",
      "| Ep:15 |Tr Loss:0.106 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "15\n",
      "| Ep:16 |Tr Loss:0.106 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "16\n",
      "| Ep:17 |Tr Loss:0.105 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "17\n",
      "| Ep:18 |Tr Loss:0.104 |Prec:0.511 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "18\n",
      "| Ep:19 |Tr Loss:0.103 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n",
      "19\n",
      "| Ep:20 |Tr Loss:0.102 |Prec:0.510 |Rec:0.157 |Tr f1:0.240 |Val prec:0.498 |Val rec:0.164 |Val f1:0.247 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 20\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |Tr f1:{train_f1:.3f} |Val prec:{valid_precision:.3f} |Val rec:{valid_recall:.3f} |Val f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading doesnt fully work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "#torch.save(model, 'filename.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN(input_dim=25002, embedding_dim=50, hidden_dim=256, output_dim=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('model.pkl'))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 50)\n",
       "  (rnn): RNN(50, 256)\n",
       "  (fc): Linear(in_features=256, out_features=126, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### easier but not so compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'modelx.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = torch.load('modelx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.235 ||Prec:0.515 |Rec:0.144 |Tr F1: 0.225 |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Tr F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use final scoring \n",
    "\n",
    "The results will be ranked according to the highest micro-averaged F1 score. This will be calculated using the f1_score function found in scikit-learn, using a command like f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document i contains the label j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
