{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data - short version 3400+ documents\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8x small size\n",
    "#reuters = pd.read_pickle('input/reuters_small8.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full data, if produced. 435 MB. NOT in Github currently. \n",
    "# You can produce this in about 30 min with preprocess_data.ipynb\n",
    "\n",
    "#reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# read classcodes\n",
    "classcodes= pd.read_csv('input/classcodes.csv')\n",
    "print(len(classcodes))\n",
    "#classcodes[0:12]\n",
    "\n",
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()\n",
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "reuters['codes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "reuters[0:3]\n",
    "# Multihot, for single list - one row\n",
    "def multihot(tags):\n",
    "    return [1 if tag in tags else 0 for tag in taglist]\n",
    "\n",
    "# list of classes, 126 int: [0...125]\n",
    "taglist = list(classcodes.index)\n",
    "Y_hot = [multihot(claslist) for claslist in reuters.codes]\n",
    "reuters['codes'] = Y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2  Official Journal contents - OJ L 190 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reuters))\n",
    "reuters[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in:\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Fields\n",
    "TEXT = data.Field()\n",
    "HEADLINE = data.Field()\n",
    "LABELS = data.LabelField(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in random order\n",
    "idx = np.random.permutation(len(reuters))\n",
    "reuters = reuters.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it\n",
    "size = len(reuters)\n",
    "train_size = int(0.7*size)\n",
    "test_size = int(0.85*size)\n",
    "\n",
    "train = reuters[0: train_size]\n",
    "val = reuters[train_size : test_size]\n",
    "test = reuters[test_size : size]\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7fc75c305710>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7fc75c305748>),\n",
       " 'codes': ('l', <torchtext.data.field.LabelField at 0x7fc75c305780>)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell torchText which Fields to apply to which json elements\n",
    "\n",
    "fields = {'headline': ('h', HEADLINE), 'text': ('t', TEXT), 'codes': ('l', LABELS)}\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (TabularDataset)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'input',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'val.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")\n",
    "# test\n",
    "#print(vars(train_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 50])\n"
     ]
    }
   ],
   "source": [
    "# GLOVE\n",
    "\n",
    "#TEXT.build_vocab(train)\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.50d\")\n",
    "HEADLINE.build_vocab(train)\n",
    "LABELS.build_vocab(train)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2398\n",
      "Number of validation examples: 514\n",
      "Number of testing examples: 514\n",
      "------------\n",
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABELS vocabulary: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print('------------')\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABELS vocabulary: {len(LABELS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 22431), ('of', 12524), ('to', 11856), ('in', 9678), ('and', 9218), ('a', 8597), ('on', 5690), ('said', 4409), ('for', 4176), ('The', 3605)]\n",
      "-----\n",
      "['<unk>', '<pad>', 'the', 'of', 'to', 'in', 'and', 'a', 'on', 'said']\n",
      "defaultdict(<function _default_unk_index at 0x7fc7796f0d90>, {'classes': 0, 'classes_pad': 1, 'codes': 2, 'headline': 3, 'text': 4})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))\n",
    "print('-----')\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABELS.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be ranked according to the highest micro-averaged F1 score. \n",
    "This will be calculated using the f1_score function found in scikit-learn, using a command like \n",
    "f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred \n",
    "the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document\n",
    "i contains the label j.\n",
    "\n",
    "Scikit:  Micro-average in F1-score\n",
    " \n",
    "'micro':\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score for BATCH\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns f1 accuracy from sklearn\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds_cpu = rounded_preds.cpu().data.numpy()\n",
    "    y_cpu = y.cpu().data.numpy()\n",
    "    f1 = f1_score(y_cpu, preds_cpu, average='micro')\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_own_accuracy(preds, y):\n",
    "    '''Returns counts of true_pos, false_pos and false_negative.\n",
    "    For counting precision, recall and F1 globally\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    '''\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds = rounded_preds.cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "        \n",
    "    # True positive\n",
    "    tpos = np.sum(np.logical_and(preds == 1, y == 1))\n",
    " \n",
    "    # True negative\n",
    "    #tneg = np.sum(np.logical_and(preds == 0, y == 0))\n",
    " \n",
    "    # False positive\n",
    "    fpos = np.sum(np.logical_and(preds == 1, y == 0))\n",
    " \n",
    "    # False negative\n",
    "    fneg = np.sum(np.logical_and(preds == 0, y == 1))\n",
    "\n",
    "    return tpos, fpos, fneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        if batch.t.shape[1] != BATCH_SIZE:\n",
    "              continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.t).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l.float())\n",
    "        \n",
    "        tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "        epoch_tpos += tpos\n",
    "        epoch_fpos += fpos\n",
    "        epoch_fneg += fneg\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "    \n",
    "    # Counted f1-score is Micro-average version\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps )\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +eps))\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            if batch.t.shape[1] != BATCH_SIZE:\n",
    "                continue\n",
    "\n",
    "            predictions = model(batch.t).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l.float())\n",
    "            \n",
    "            tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "            epoch_tpos += tpos\n",
    "            epoch_fpos += fpos\n",
    "            epoch_fneg += fneg            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            #epoch_acc += acc.item()\n",
    "\n",
    "    # avoid div by zero with epsilon\n",
    "    eps = 1e-7\n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos +eps)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg +eps)\n",
    "    epoch_f1 = 2* (  ((epoch_precision * epoch_recall)+eps) / (epoch_precision + epoch_recall +eps))            \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import models\n",
    "#from models import *\n",
    "\n",
    "# Common\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "OUTPUT_DIM = 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 200\n",
    "FILTER_SIZES = [3,5,7]\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = models.CNN2(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "# 14 epochs gave f1 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or LSTM\n",
    "HIDDEN_DIM = 250\n",
    "OUTPUT_DIM = 126\n",
    "N_EPOCHS = 50\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = models.LSTM(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, BIDIRECTIONAL, device)\n",
    "model.hidden = model.init_hidden(64)\n",
    "\n",
    "\n",
    "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 4\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 10\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |f1:{train_f1:.3f} |Val Loss:{valid_loss:.3f} |prec:{valid_precision:.3f} |rec:{valid_recall:.3f} |f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this version create the model object with same paramters as when training. Then load weights.\n",
    "This version saves also gradients etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "#torch.save(model, 'filename.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN(input_dim=25002, embedding_dim=50, hidden_dim=256, output_dim=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('model.pkl'))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### easier but not so compatible\n",
    "This version does not save the gradients, only final model. \n",
    "Here you dont ened to create model object frist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'modelx.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = torch.load('modelx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Test F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use final scoring \n",
    "\n",
    "The results will be ranked according to the highest micro-averaged F1 score. This will be calculated using the f1_score function found in scikit-learn, using a command like f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document i contains the label j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
