{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C18, C181, CCAT]</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ C 221 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[G15, GCAT]</td>\n",
       "      <td>Official Journal contents - OJ C 220 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               codes                                           headline  \\\n",
       "0  [C18, C181, CCAT]    Eureko is latest suitor for French insurer GAN.   \n",
       "1        [G15, GCAT]  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2        [G15, GCAT]  Official Journal contents - OJ L 190 of July 1...   \n",
       "3        [G15, GCAT]  Official Journal contents - OJ C 221 of July 1...   \n",
       "4        [G15, GCAT]  Official Journal contents - OJ C 220 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "3  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "4  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "3   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "4   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data - short version 3400+ documents\n",
    "reuters = pd.read_pickle('input/reuters_small.pkl')\n",
    "print(len(reuters))\n",
    "reuters[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full data, if produced. 435 MB. NOT in Github currently. \n",
    "# You can produce this in about 30 min with preprocess_data.ipynb\n",
    "\n",
    "#reuters = pd.read_pickle('input/reuters_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# read classcodes\n",
    "classcodes= pd.read_csv('input/classcodes.csv')\n",
    "print(len(classcodes))\n",
    "#classcodes[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index field to DataFrame\n",
    "classcodes = classcodes.reset_index()\n",
    "# Create dictionary index/int to classcode and classcode to int\n",
    "itocode = dict(zip(classcodes.index, classcodes.Code))\n",
    "codetoi = dict(zip(classcodes.Code, classcodes.index))\n",
    "def listToInt(mylist):\n",
    "    return [codetoi[item] for item in mylist]\n",
    "\n",
    "reuters['codes'] = [listToInt(codelist) for codelist in reuters.codes]\n",
    "reuters[0:3]\n",
    "# Multihot, for single list - one row\n",
    "def multihot(tags):\n",
    "    return [1 if tag in tags else 0 for tag in taglist]\n",
    "\n",
    "# list of classes, 126 int: [0...125]\n",
    "taglist = list(classcodes.index)\n",
    "Y_hot = [multihot(claslist) for claslist in reuters.codes]\n",
    "reuters['codes'] = Y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 221 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 220 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2  Official Journal contents - OJ L 190 of July 1...   \n",
       "3  Official Journal contents - OJ C 221 of July 1...   \n",
       "4  Official Journal contents - OJ C 220 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "3  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "4  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "3   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "4   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in:\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "#Define the Fields\n",
    "TEXT = data.Field()\n",
    "HEADLINE = data.Field()\n",
    "\n",
    "LABELS = data.LabelField(sequential=False, use_vocab=False)\n",
    "#CLASSES = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Eureko is latest suitor for French insurer GAN.</td>\n",
       "      <td>\\nEureko, an alliance of six European financia...</td>\n",
       "      <td>[25, 26, 44]</td>\n",
       "      <td>[25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Reuter EC Report Long-Term Diary for July 28 -...</td>\n",
       "      <td>\\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ L 190 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 221 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Official Journal contents - OJ C 220 of July 1...</td>\n",
       "      <td>\\n*\\n(Note - contents are displayed in reverse...</td>\n",
       "      <td>[80, 90]</td>\n",
       "      <td>[80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               codes  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0    Eureko is latest suitor for French insurer GAN.   \n",
       "1  Reuter EC Report Long-Term Diary for July 28 -...   \n",
       "2  Official Journal contents - OJ L 190 of July 1...   \n",
       "3  Official Journal contents - OJ C 221 of July 1...   \n",
       "4  Official Journal contents - OJ C 220 of July 1...   \n",
       "\n",
       "                                                text       classes  \\\n",
       "0  \\nEureko, an alliance of six European financia...  [25, 26, 44]   \n",
       "1  \\n****\\nHIGHLIGHTS\\n****\\nLUXEMBOURG - Luxembo...      [80, 90]   \n",
       "2  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "3  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "4  \\n*\\n(Note - contents are displayed in reverse...      [80, 90]   \n",
       "\n",
       "                                         classes_pad  \n",
       "0  [25, 26, 44, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "1   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "2   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "3   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  \n",
       "4   [80, 90, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test, save pd df to JSON\n",
    "                            # one record at time, one record by line\n",
    "reuters.to_json('input/reuters_small.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it\n",
    "train = reuters[0:2500]\n",
    "test = reuters[2500:3000]\n",
    "val = reuters[3000:len(reuters)]\n",
    "\n",
    "train.to_json('input/train.json', orient='records', lines=True)\n",
    "test.to_json('input/test.json', orient='records', lines=True)\n",
    "val.to_json('input/val.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell torchText which Fields to apply to which json elements\n",
    "\n",
    "fields = {'headline': ('h', HEADLINE), 'text': ('t', TEXT), 'codes': ('l', LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': ('h', <torchtext.data.field.Field at 0x7f2ba84189b0>),\n",
       " 'text': ('t', <torchtext.data.field.Field at 0x7f2ba8418860>),\n",
       " 'codes': ('l', <torchtext.data.field.LabelField at 0x7f2ba8418a58>)}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (TabularDataset)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'input',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'val.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "#print(vars(train_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device('cpu')\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes=(16, 256, 256),\n",
    "    sort_key=lambda x: len(x.text), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "HEADLINE.build_vocab(train)\n",
    "LABELS.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7f2ba8418828>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2500\n",
      "Number of validation examples: 426\n",
      "Number of testing examples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=25000)\n",
    "LABELS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABELS vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABELS vocabulary: {len(LABELS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 22529), ('of', 12791), ('to', 12004), ('and', 9792), ('in', 9599), ('a', 8831), ('on', 5491), ('said', 4417), ('for', 4282), ('The', 3677)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'of', 'to', 'and', 'in', 'a', 'on', 'said']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f2ba85bf268>, {0: 0, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABELS.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_key= lambda x: len(x.t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 126\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will be ranked according to the highest micro-averaged F1 score. \n",
    "This will be calculated using the f1_score function found in scikit-learn, using a command like \n",
    "f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred \n",
    "the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document\n",
    "i contains the label j.\n",
    "\n",
    "Scikit:  Micro-average in F1-score\n",
    " \n",
    "'micro':\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score for BATCH\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns f1 accuracy from sklearn\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds_cpu = rounded_preds.cpu().data.numpy()\n",
    "    y_cpu = y.cpu().data.numpy()\n",
    "    f1 = f1_score(y_cpu, preds_cpu, average='micro')\n",
    "    return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f1_own_accuracy(preds, y):\n",
    "    '''Returns counts of true_pos, false_pos and false_negative.\n",
    "    For counting precision, recall and F1 globally\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    '''\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    preds = rounded_preds.cpu().data.numpy()\n",
    "    y = y.cpu().data.numpy()\n",
    "        \n",
    "    # True positive\n",
    "    tpos = np.sum(np.logical_and(preds == 1, y == 1))\n",
    " \n",
    "    # True negative\n",
    "    #tneg = np.sum(np.logical_and(preds == 0, y == 0))\n",
    " \n",
    "    # False positive\n",
    "    fpos = np.sum(np.logical_and(preds == 1, y == 0))\n",
    " \n",
    "    # False negative\n",
    "    fneg = np.sum(np.logical_and(preds == 0, y == 1))\n",
    "\n",
    "    return tpos, fpos, fneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    \n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.t).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.l.float())\n",
    "        \n",
    "        tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "        epoch_tpos += tpos\n",
    "        epoch_fpos += fpos\n",
    "        epoch_fneg += fneg\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "        \n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg)\n",
    "    epoch_f1 = 2* (  (epoch_precision * epoch_recall) / (epoch_precision + epoch_recall))\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 version\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #epoch_acc = 0\n",
    "    epoch_tpos = 0\n",
    "    epoch_fpos = 0\n",
    "    epoch_fneg = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.t).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.l.float())\n",
    "            \n",
    "            tpos, fpos, fneg = f1_own_accuracy(predictions, batch.l.float())\n",
    "            epoch_tpos += tpos\n",
    "            epoch_fpos += fpos\n",
    "            epoch_fneg += fneg            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            #epoch_acc += acc.item()\n",
    "            \n",
    "    epoch_precision = epoch_tpos / (epoch_tpos + epoch_fpos)\n",
    "    epoch_recall = epoch_tpos / (epoch_tpos + epoch_fneg)\n",
    "    epoch_f1 = 2* (  (epoch_precision * epoch_recall) / (epoch_precision + epoch_recall))            \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_precision, epoch_recall, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.691 |Prec:0.013 |Rec:0.232 |Tr f1:0.025 |Val prec:0.014 |Val rec:0.262 |Val f1:0.027 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.687 |Prec:0.014 |Rec:0.230 |Tr f1:0.026 |Val prec:0.015 |Val rec:0.259 |Val f1:0.028 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.682 |Prec:0.014 |Rec:0.229 |Tr f1:0.026 |Val prec:0.015 |Val rec:0.247 |Val f1:0.028 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.677 |Prec:0.015 |Rec:0.224 |Tr f1:0.028 |Val prec:0.014 |Val rec:0.216 |Val f1:0.026 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 4\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |Tr f1:{train_f1:.3f} |Val prec:{valid_precision:.3f} |Val rec:{valid_recall:.3f} |Val f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...120 epochs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "| Ep:01 |Tr Loss:0.673 |Prec:0.014 |Rec:0.195 |Tr f1:0.027 |Val prec:0.013 |Val rec:0.191 |Val f1:0.025 |\n",
      "1\n",
      "| Ep:02 |Tr Loss:0.669 |Prec:0.014 |Rec:0.169 |Tr f1:0.025 |Val prec:0.013 |Val rec:0.168 |Val f1:0.024 |\n",
      "2\n",
      "| Ep:03 |Tr Loss:0.664 |Prec:0.013 |Rec:0.161 |Tr f1:0.025 |Val prec:0.013 |Val rec:0.167 |Val f1:0.024 |\n",
      "3\n",
      "| Ep:04 |Tr Loss:0.660 |Prec:0.013 |Rec:0.161 |Tr f1:0.025 |Val prec:0.013 |Val rec:0.167 |Val f1:0.024 |\n",
      "4\n",
      "| Ep:05 |Tr Loss:0.655 |Prec:0.014 |Rec:0.159 |Tr f1:0.025 |Val prec:0.013 |Val rec:0.157 |Val f1:0.023 |\n",
      "5\n",
      "| Ep:06 |Tr Loss:0.651 |Prec:0.014 |Rec:0.154 |Tr f1:0.025 |Val prec:0.013 |Val rec:0.156 |Val f1:0.024 |\n",
      "6\n",
      "| Ep:07 |Tr Loss:0.647 |Prec:0.014 |Rec:0.151 |Tr f1:0.026 |Val prec:0.014 |Val rec:0.152 |Val f1:0.025 |\n",
      "7\n",
      "| Ep:08 |Tr Loss:0.642 |Prec:0.015 |Rec:0.148 |Tr f1:0.027 |Val prec:0.014 |Val rec:0.149 |Val f1:0.026 |\n",
      "8\n",
      "| Ep:09 |Tr Loss:0.638 |Prec:0.014 |Rec:0.131 |Tr f1:0.025 |Val prec:0.012 |Val rec:0.121 |Val f1:0.022 |\n",
      "9\n",
      "| Ep:10 |Tr Loss:0.634 |Prec:0.011 |Rec:0.094 |Tr f1:0.020 |Val prec:0.011 |Val rec:0.098 |Val f1:0.020 |\n",
      "10\n",
      "| Ep:11 |Tr Loss:0.629 |Prec:0.010 |Rec:0.083 |Tr f1:0.018 |Val prec:0.011 |Val rec:0.098 |Val f1:0.020 |\n",
      "11\n",
      "| Ep:12 |Tr Loss:0.625 |Prec:0.011 |Rec:0.083 |Tr f1:0.019 |Val prec:0.012 |Val rec:0.095 |Val f1:0.021 |\n",
      "12\n",
      "| Ep:13 |Tr Loss:0.621 |Prec:0.011 |Rec:0.080 |Tr f1:0.019 |Val prec:0.012 |Val rec:0.093 |Val f1:0.021 |\n",
      "13\n",
      "| Ep:14 |Tr Loss:0.617 |Prec:0.011 |Rec:0.078 |Tr f1:0.019 |Val prec:0.012 |Val rec:0.088 |Val f1:0.021 |\n",
      "14\n",
      "| Ep:15 |Tr Loss:0.612 |Prec:0.011 |Rec:0.074 |Tr f1:0.019 |Val prec:0.012 |Val rec:0.088 |Val f1:0.021 |\n",
      "15\n",
      "| Ep:16 |Tr Loss:0.608 |Prec:0.011 |Rec:0.072 |Tr f1:0.019 |Val prec:0.012 |Val rec:0.084 |Val f1:0.021 |\n",
      "16\n",
      "| Ep:17 |Tr Loss:0.604 |Prec:0.011 |Rec:0.072 |Tr f1:0.020 |Val prec:0.012 |Val rec:0.083 |Val f1:0.021 |\n",
      "17\n",
      "| Ep:18 |Tr Loss:0.600 |Prec:0.012 |Rec:0.071 |Tr f1:0.020 |Val prec:0.014 |Val rec:0.082 |Val f1:0.024 |\n",
      "18\n",
      "| Ep:19 |Tr Loss:0.596 |Prec:0.012 |Rec:0.060 |Tr f1:0.020 |Val prec:0.011 |Val rec:0.058 |Val f1:0.018 |\n",
      "19\n",
      "| Ep:20 |Tr Loss:0.591 |Prec:0.010 |Rec:0.041 |Tr f1:0.015 |Val prec:0.010 |Val rec:0.038 |Val f1:0.015 |\n"
     ]
    }
   ],
   "source": [
    "# Ver2 - F1\n",
    "N_EPOCHS = 20\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #print(f'| Epoch:{epoch+1:02} | Train Loss: {train_loss:.3f} | Tr Precision: {train_precision:.3f} | Tr recall: {train_recall:.3f} | Tr f1: {train_f1:.3f} | Valid f1: {valid_f1:.3f} |')    \n",
    "    print(f'| Ep:{epoch+1:02} |Tr Loss:{train_loss:.3f} |Prec:{train_precision:.3f} |Rec:{train_recall:.3f} |Tr f1:{train_f1:.3f} |Val prec:{valid_precision:.3f} |Val rec:{valid_recall:.3f} |Val f1:{valid_f1:.3f} |')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading doesnt fully work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "#torch.save(model, 'filename.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN(input_dim=25002, embedding_dim=50, hidden_dim=256, output_dim=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('model.pkl'))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 50)\n",
       "  (rnn): RNN(50, 256)\n",
       "  (fc): Linear(in_features=256, out_features=126, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### easier but not so compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'modelx.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = torch.load('modelx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.591 ||Prec:0.015 |Rec:0.050 |Tr F1: 0.023 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(modelx, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Tr F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.539 ||Prec:0.061 |Rec:0.091 |Tr F1: 0.073 |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_precision, test_recall, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} ||Prec:{test_precision:.3f} |Rec:{test_recall:.3f} |Tr F1:{test_f1: .3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use final scoring \n",
    "\n",
    "The results will be ranked according to the highest micro-averaged F1 score. This will be calculated using the f1_score function found in scikit-learn, using a command like f1_score(y_true, y_pred, average='micro') where y_true is the matrix with the ground truth, and y_pred the predicted output. Both matrices are binary, a 1 in row i and column j means that the image/document i contains the label j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
